{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from robingrad import Tensor, draw_dot\n",
    "import robingrad.nn as nn\n",
    "import torch\n",
    "from sklearn.datasets import make_regression\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200, 5)\n",
      "(200,)\n",
      "[0.95927083 0.02451017 0.49799829 1.45114361 2.15318246]\n",
      "[172.54436082 -52.9529574   -4.14935233 193.99958991 -66.96262773]\n"
     ]
    }
   ],
   "source": [
    "X, y = make_regression(n_samples=200, n_features=5, n_targets=1, random_state=42)\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "print(X[0])\n",
    "print(y[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'robingrad.tensor.Tensor'> (200, 5)\n",
      "<class 'robingrad.tensor.Tensor'> (200, 1)\n"
     ]
    }
   ],
   "source": [
    "X_train = Tensor(X, requires_grad=True)\n",
    "print(type(X_train), X_train.shape)\n",
    "y_train = Tensor(y, requires_grad=True).reshape((200,1))\n",
    "print(type(y_train), y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TinyNet:\n",
    "    def __init__(self):\n",
    "        self.l1 = nn.Linear(5,16)\n",
    "        self.l2 = nn.Linear(16,1)\n",
    "    def __call__(self, x):\n",
    "        x = self.l1(x)\n",
    "        x = x.relu()\n",
    "        x = self.l2(x)\n",
    "        return x\n",
    "        \n",
    "net = TinyNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "matmul: Input operand 1 has a mismatch in its core dimension 0, with gufunc signature (n?,k),(k,m?)->(n?,m?) (size 16 is different from 5)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [5]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mnet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m res\n",
      "Input \u001b[0;32mIn [4]\u001b[0m, in \u001b[0;36mTinyNet.__call__\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m----> 6\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43ml1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m     x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mrelu()\n\u001b[1;32m      8\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39ml2(x)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/robingrad/nn/__init__.py:10\u001b[0m, in \u001b[0;36mLinear.__call__\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTensor\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTensor\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m---> 10\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m@\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias:\n\u001b[1;32m     12\u001b[0m         out \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/robingrad/tensor.py:150\u001b[0m, in \u001b[0;36mTensor.__matmul__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__matmul__\u001b[39m(\u001b[38;5;28mself\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTensor\u001b[39m\u001b[38;5;124m\"\u001b[39m, other: Union[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTensor\u001b[39m\u001b[38;5;124m\"\u001b[39m, np\u001b[38;5;241m.\u001b[39mndarray, List, \u001b[38;5;28mint\u001b[39m, \u001b[38;5;28mfloat\u001b[39m]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTensor\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    149\u001b[0m     other \u001b[38;5;241m=\u001b[39m other \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(other, Tensor) \u001b[38;5;28;01melse\u001b[39;00m Tensor(other, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mdtype, requires_grad\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequires_grad)\n\u001b[0;32m--> 150\u001b[0m     out \u001b[38;5;241m=\u001b[39m Tensor(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m@\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mdtype, _children\u001b[38;5;241m=\u001b[39m(\u001b[38;5;28mself\u001b[39m, other), _op\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m@\u001b[39m\u001b[38;5;124m'\u001b[39m, _origin\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__matmul__\u001b[39m\u001b[38;5;124m\"\u001b[39m, requires_grad\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequires_grad)\n\u001b[1;32m    152\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_backward\u001b[39m():\n\u001b[1;32m    153\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgrad \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m out\u001b[38;5;241m.\u001b[39mgrad \u001b[38;5;241m@\u001b[39m other\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mT\n",
      "\u001b[0;31mValueError\u001b[0m: matmul: Input operand 1 has a mismatch in its core dimension 0, with gufunc signature (n?,k),(k,m?)->(n?,m?) (size 16 is different from 5)"
     ]
    }
   ],
   "source": [
    "res = net(X_train[0])\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_dot(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# epochs = 100\n",
    "# for epoch in range(epochs):\n",
    "#     y_pred = []\n",
    "#     losses = []\n",
    "#     s = time.monotonic()\n",
    "#     for i in range(X_train.shape[0]):\n",
    "#         output = net(X_train[i])\n",
    "#         y_pred.append(output.data)\n",
    "#         target = y_train[i]\n",
    "#         loss = (output-target)**2\n",
    "#         losses.append(loss.data)\n",
    "#         loss.backward()\n",
    "#         for p in [net.l1.weight, net.l1.bias, net.l2.weight, net.l2.bias, net.l3.weight, net.l3.bias]:\n",
    "#             p.data += -3e-4*p.grad\n",
    "#         for p in [net.l1.weight, net.l1.bias, net.l2.weight, net.l2.bias, net.l3.weight, net.l3.bias]:\n",
    "#             p.grad = np.zeros_like(p.grad)\n",
    "#     e = time.monotonic()\n",
    "#     t = e - s\n",
    "#     loss_epoch = sum(losses)/ len(losses)\n",
    "#     r2 = r2_score(y, y_pred)\n",
    "#     if epoch % 10 == 0 or epoch == epochs-1:\n",
    "#         print(f\"epoch: {epoch} | loss: {loss_epoch:.2f} | R2: {r2:.2f} | time: {t:.2f} sec.\")\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
